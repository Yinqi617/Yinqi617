{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Lecture 3.2. In this exercise, you will train several ensemble models such as Random Forest, Gradient Boosting and XGBoost. Then you need to combine these models to implement stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "# skip all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be using [MNIST database](https://en.wikipedia.org/wiki/MNIST_database) as our training dataset. First, let's load mnist data from `sklearn.datasets`. Then, you will split 70000 data instances into training set (50000), validation set (10000) and test set (10000). You should use training set to train model and validation set to evaluate the model. Then you compare the various models to find the best one. Once you have found it, try it on test set. Note that we will not include much hyperparameters tuning in this notebook. We will do it in next Lecture. \n",
    "\n",
    "\n",
    "* Use `sklearn.model_selection.train_test_split()`.\n",
    "* You can split twice. For the first split, you get `train_val` and `test`. Then you split `train_val` to get `train` and `test`.\n",
    "* Both of the `random_state` should be set to 42.\n",
    "* Name them **X_train, y_train, X_val, y_val, X_test, y_test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data from sklearn\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X, y = mnist['data'], mnist['target']\n",
    "\n",
    "# first split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=10000, random_state=42)\n",
    "\n",
    "# second split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest, Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to initialize two classification models. We will train models in section 4. \n",
    "* [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) \n",
    "* [Gradient Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "\n",
    "Random Forest and Gradient Boosting are both in `sklearn.ensemble`. The hyperparameters of these two models has already been assigned for you. Again, you might tune them by hand or using [GridSearchCV()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), but this is not our objective today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest hyperparameters, DO NOT MODIFY\n",
    "n_estimators = 50\n",
    "max_depth = None\n",
    "min_samples_split = 2\n",
    "max_leaf_nodes = None\n",
    "random_state=42\n",
    "\n",
    "# initialize a Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                max_leaf_nodes=max_leaf_nodes, \n",
    "                                max_depth=max_depth, \n",
    "                                min_samples_split=min_samples_split,\n",
    "                                random_state=random_state,\n",
    "                                verbose=True,\n",
    "                                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Gradient Boosting hyperparameters, DO NOT MODIFY\n",
    "n_estimators = 30 # you might change to a higher one\n",
    "learning_rate = 0.3\n",
    "min_samples_split = 0.01\n",
    "min_samples_leaf = 10\n",
    "max_depth = 2\n",
    "subsample = 0.8\n",
    "random_state=42\n",
    "\n",
    "# initialize a Gradient Boosting Classifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=n_estimators, \n",
    "                                    learning_rate=learning_rate,\n",
    "                                    min_samples_split=min_samples_split,\n",
    "                                    min_samples_leaf=min_samples_leaf, \n",
    "                                    max_depth=max_depth, \n",
    "                                    subsample=subsample,\n",
    "                                    random_state=random_state,\n",
    "                                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[XGBoost](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/) (e$X$treme $G$radient $Boost$ing) is an advanced implementation of gradient boosting algorithm. It has become the ultimate weapon of many data scientist. I highly recommend to use XGboost, if things donâ€™t go your way in predictive modeling. Building a XGBoost model is very easy, but improving it is difficult. Thus hyperparameter tuning is must for XGBoost. \n",
    "\n",
    "XGBoost has many advantages. Here I list four important advantages, which might be useful for interview.\n",
    "1. **Regularization**. Standard GBM implementation has no regularization, which is easy to overfitting. Regularization helps XGBoost to reduce overfitting.\n",
    "2. **Parallel Processing**. XGBoost is faster compared to GBM. To explore details, check [this](http://zhanpengfang.github.io/418home.html).\n",
    "3. **Handling Missing Values**. XGBoost has an in-built routine to handle missing values.\n",
    "4. **Built-in Cross-Validation**. XGBoost allows user to run a cross-validation at each iteration of the boosting process and thus it is easy to get the exact optimum number of boosting iterations in a single run.\n",
    "\n",
    "****\n",
    "\n",
    "In Python, there is a Scikit-Learn API for XGBoost, making it easier to implement. As before, I have set up hyperparameters for you. This can be the start points. But in reality or in Kaggle Competition, you should tune hyperparameters very carefully for XGBoost. Now let's initialize XGBoost and train it in next section.\n",
    "\n",
    "* [XGBoost](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)\n",
    "\n",
    "\n",
    "**NOTE:** You should install xgboost package before using it. Run `pip install xgboost` in your terminal, or `! pip install xgboost` in this jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "# XGBoost hyperparameters, DO NOT MODIFY\n",
    "n_estimators = 30 # you might change to a higher one\n",
    "learning_rate = 0.3\n",
    "max_depth = 2\n",
    "min_child_weight = 5\n",
    "gamma = 0.1\n",
    "subsample = 0.8\n",
    "random_state = 42\n",
    "\n",
    "# initialize a XGBoost Classifier\n",
    "xgb_clf = xgboost.XGBClassifier(n_estimators=n_estimators, \n",
    "                                learning_rate=learning_rate,\n",
    "                                max_depth=max_depth, \n",
    "                                min_child_weight=min_child_weight,\n",
    "                                gamma=gamma,\n",
    "                                subsample=subsample,\n",
    "                                random_state=random_state,\n",
    "                                verbosity=2,\n",
    "                                n_jobs=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacking idea is very simple. Instead of using trivial functions (such as hard voting) to aggregate the results of all estimators, we can train a model (meta-estimator) to perform this aggregation. As shown in the picture below,\n",
    "\n",
    "* First, the individual classification models are trained based on the training set. \n",
    "* Then we predict on validation set `X_val`, named `X_val_predictions`.\n",
    "* Third, a meta-classifier is fitted based on `X_val_predictions` and `y_val`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: [StackingClassifier](http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/)\n",
    "<img src=\"./test/stacking.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Individual Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's train three individual models and print out the accuracy score on validation set. It might take a long time to run Gradient Boosting and XGBoost. Thus, you should record accuracy scores as well as running time for each model. Here are some results of Gradient Boosting Classifier for your reference. Generally, there is a positive correlation between running time and number of estimators. Also the accuracy score increases significantly when number of estimators is larger. You may choose `n_estimator` up to 500 for Gradient Boosting or XGBoost, if you have a strong machine or you would like to spend a long time training model. But here I suggest you choose 30. After you go over all the cells in this notebook, you might choose a higher one. \n",
    "\n",
    "* n_estimators = 10, run ~5 mins, score ~0.85\n",
    "* n_estimators = 30, run ~10 mins, score ~0.91\n",
    "* n_estimators = 100, run ~50 mins, score ~0.94\n",
    "* n_estimators = 200, run ~2 hours, score ~0.96\n",
    "* n_estimators = 500, run ~4 hours, score ~0.97\n",
    "\n",
    "**NOTE:** In reality we use cross validation to tune hyperparameters, which will definitely spend tons of time for Gradient Boosting. One efficient way to solve this time-consuming problem is to down-sampling your training data. We will soon meet this problem in Kaggle Competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "estimators = [rf_clf, gb_clf, xgb_clf]\n",
    "scores = []\n",
    "times = []\n",
    "for estimator in estimators:\n",
    "    # record start time\n",
    "    start = time.time()\n",
    "    # fit data for each classifier\n",
    "    estimator.fit(X_train, y_train)\n",
    "    # save spend time\n",
    "    times.append(time.time()-start)\n",
    "    # save accuracy score\n",
    "    scores.append(estimator.score(X_val, y_val))\n",
    "\n",
    "print (\"Accuracy scores for Random Forest, Gradient Boosting and XGBoost are:\")\n",
    "print (scores)\n",
    "print (\"Running time for Random Forest, Gradient Boosting and XGBoost are:\")\n",
    "print (times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's stack three models to get a new one. First, we get the predictions on validation set. Each model will have a list of prediction results. We vertically append those lists of results as `X_val_predictions`. To be specific, we initialize an empty array, which has the shape of `(number of samples in X_val, number of estimators)`. Then we make prediction one by one and insert the results into the right position. \n",
    "\n",
    "For the meta-classifier, we use Random Forest model. To compare with other models, we should take a look at the oob score of this Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype=np.float32)\n",
    "\n",
    "# insert results to X_val_predictions\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)\n",
    "\n",
    "# initialize meta classifier\n",
    "meta_clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
    "\n",
    "# fit X_val_predictions and y_val\n",
    "meta_clf.fit(X_val_predictions, y_val)\n",
    "\n",
    "# compute oob score of meta classifier\n",
    "oob_score = meta_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might see that stacking is not as good as using single Random Forest Classifier. The reason is that we only use one pair of train/validate in stacking. Actually, we should use Stacking Cross Validation in order to get a more accurate result. Here we only introduce what is stacking and how to implement a simple stacking model. We will go into details in Lecture 3.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance On Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, let's compare the performance of all models on test set. For stacking, we need to get `X_test_predictions` using the same way as getting `X_val_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# initialize X_test_predictions\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype=np.float32)\n",
    "\n",
    "# get X_test_predictions\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "\n",
    "# record accuracy scores of four models\n",
    "test_scores = []\n",
    "\n",
    "# compute scores for individual classifiers\n",
    "for estimator in estimators:\n",
    "    # save accuracy score\n",
    "    test_scores.append(estimator.score(X_test, y_test))\n",
    "\n",
    "# predict on X_test_predictions using meta_clf \n",
    "y_pred_meta = meta_clf.predict(X_test_predictions)\n",
    "\n",
    "# append accuracy score of meta classifier\n",
    "test_scores.append(accuracy_score(y_test, y_pred_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
